{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3a01fa63-9dee-468c-ae1a-57241f132018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 2s 65ms/step - loss: 0.6063 - accuracy: 0.7720 - precision: 0.8157 - recall: 0.7042 - val_loss: 0.5742 - val_accuracy: 0.8310 - val_precision: 0.8543 - val_recall: 0.7939\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5526 - accuracy: 0.8435 - precision: 0.8791 - recall: 0.7975 - val_loss: 0.5238 - val_accuracy: 0.8790 - val_precision: 0.9101 - val_recall: 0.8384\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5047 - accuracy: 0.8913 - precision: 0.9132 - recall: 0.8653 - val_loss: 0.4786 - val_accuracy: 0.9070 - val_precision: 0.9295 - val_recall: 0.8788\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4614 - accuracy: 0.9208 - precision: 0.9378 - recall: 0.9017 - val_loss: 0.4378 - val_accuracy: 0.9340 - val_precision: 0.9459 - val_recall: 0.9192\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4223 - accuracy: 0.9390 - precision: 0.9518 - recall: 0.9252 - val_loss: 0.4009 - val_accuracy: 0.9490 - val_precision: 0.9625 - val_recall: 0.9333\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3869 - accuracy: 0.9523 - precision: 0.9599 - recall: 0.9441 - val_loss: 0.3673 - val_accuracy: 0.9610 - val_precision: 0.9711 - val_recall: 0.9495\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3547 - accuracy: 0.9595 - precision: 0.9661 - recall: 0.9526 - val_loss: 0.3365 - val_accuracy: 0.9640 - val_precision: 0.9732 - val_recall: 0.9535\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3252 - accuracy: 0.9647 - precision: 0.9712 - recall: 0.9581 - val_loss: 0.3084 - val_accuracy: 0.9700 - val_precision: 0.9794 - val_recall: 0.9596\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2981 - accuracy: 0.9695 - precision: 0.9757 - recall: 0.9631 - val_loss: 0.2825 - val_accuracy: 0.9750 - val_precision: 0.9835 - val_recall: 0.9657\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2732 - accuracy: 0.9720 - precision: 0.9792 - recall: 0.9646 - val_loss: 0.2588 - val_accuracy: 0.9760 - val_precision: 0.9856 - val_recall: 0.9657\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.2583 - accuracy: 0.9718 - precision: 0.9743 - recall: 0.9692\n",
      "Test Accuracy: 0.9718\n",
      "Test Precision: 0.9743\n",
      "Test Recall: 0.9692\n"
     ]
    }
   ],
   "source": [
    "# train_fraud_model.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('data.csv')  # Replace with your file path\n",
    "\n",
    "# Features and target\n",
    "X = data[['Hour_of_Day', 'Amount', 'V1', 'V2', 'V3', 'V4', 'V5',\n",
    "          'Merchant_Type', 'Location_Distance', 'Transaction_Frequency',\n",
    "          'Is_International', 'Device_Type']]\n",
    "y = data['Class']\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = ['Hour_of_Day', 'Amount', 'V1', 'V2', 'V3', 'V4', 'V5',\n",
    "                    'Location_Distance', 'Transaction_Frequency', 'Is_International']\n",
    "categorical_features = ['Merchant_Type', 'Device_Type']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# Fit and transform features\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Save the preprocessor\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.5, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=512,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {results[1]:.4f}')\n",
    "print(f'Test Precision: {results[2]:.4f}')\n",
    "print(f'Test Recall: {results[3]:.4f}')\n",
    "\n",
    "# Save the model\n",
    "model.save('fraud_modelx.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1d8be773-ff33-4d31-adcb-71c9e41868db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Score: 0.1969 (19.69%) => Not Fraud\n",
      "Risk Level: Very Low Risk\n"
     ]
    }
   ],
   "source": [
    "# predict_fraud.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define feature names\n",
    "numeric_features = ['Hour_of_Day', 'Amount', 'V1', 'V2', 'V3', 'V4', 'V5',\n",
    "                    'Location_Distance', 'Transaction_Frequency', 'Is_International']\n",
    "categorical_features = ['Merchant_Type', 'Device_Type']\n",
    "\n",
    "# Load the trained model and preprocessor\n",
    "model = load_model('fraud_modelx.h5')\n",
    "preprocessor = joblib.load('preprocessor.pkl')\n",
    "\n",
    "# Risk level helper\n",
    "def get_risk_level(score):\n",
    "    if score >= 0.85:\n",
    "        return 'High Risk'\n",
    "    elif score >= 0.5:\n",
    "        return 'Medium Risk'\n",
    "    elif score >= 0.2:\n",
    "        return 'Low Risk'\n",
    "    else:\n",
    "        return 'Very Low Risk'\n",
    "\n",
    "# Prediction function\n",
    "def predict_fraud(user_input: dict):\n",
    "    \"\"\"\n",
    "    Predict if a transaction is fraud or not.\n",
    "    user_input: dict with keys matching the model features\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([user_input])\n",
    "    X_processed = preprocessor.transform(df)\n",
    "    prediction = model.predict(X_processed)[0][0]\n",
    "    result = 'Fraud' if prediction >= 0.5 else 'Not Fraud'\n",
    "    risk_level = get_risk_level(prediction)\n",
    "    print(f\"Prediction Score: {prediction:.4f} ({prediction*100:.2f}%) => {result}\")\n",
    "    print(f\"Risk Level: {risk_level}\")\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    input_data = {\n",
    "        'Hour_of_Day': 10,\n",
    "        'Amount': 30,\n",
    "        'V1': 0.2,\n",
    "        'V2': -0.1,\n",
    "        'V3': 0.3,\n",
    "        'V4': -0.1,\n",
    "        'V5': 0,\n",
    "        'Merchant_Type': 'Retail',\n",
    "        'Location_Distance': 5,\n",
    "        'Transaction_Frequency': 1,\n",
    "        'Is_International': 0,\n",
    "        'Device_Type': 'Desktop'\n",
    "    }\n",
    "\n",
    "    predict_fraud(input_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-GPU]",
   "language": "python",
   "name": "conda-env-.conda-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
